{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "acting-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVER_URL=https://dataverse.ucla.edu\n",
    "#PERSISTENT_IDENTIFIER=doi:10.25346/S6/T4LHZF\n",
    "#SIZE=10000000\n",
    "#\n",
    "# token set programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "robust-chambers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json   # used to pull in dataverse token\n",
    "import requests  # http://docs.python-requests.org/en/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "warming-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Update the 4 params below to run this code\n",
    "# --------------------------------------------------\n",
    "dataverse_server = 'https://dataverse.ucla.edu' # no trailing slash\n",
    "dataset_id = 1  # database id of the dataset\n",
    "persistentId = 'doi:10.25346/S6/T4LHZF' # doi or hdl of the dataset   10.25346/S6/T4LHZF,\n",
    "size=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "abstract-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api in separate file\n",
    "with open(\"config.json\") as config:\n",
    "    cfg = json.load(config)\n",
    "# load either dataverse_production or dataverse_test\n",
    "api_key = cfg['dataverse_production']['api_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "secondary-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Prepare \"file\"\n",
    "# --------------------------------------------------\n",
    "file_content = 'content: %s' % datetime.now()\n",
    "files = {'file': ('sample_file.txt', file_content)}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Using a \"jsonData\" parameter, add optional description + file tags\n",
    "# --------------------------------------------------\n",
    "params = dict(description=\"LARIAC4\", categories=[\"LARIAC4\", \"GIS\",\"LAS file\", \"Lidar\"], contentType=\"LAS file Lidar\", restrict=True)\n",
    "\n",
    "params_as_json_string = json.dumps(params)\n",
    "\n",
    "payload = dict(jsonData=params_as_json_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "written-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's persistentId (e.g. doi, hdl, etc)\n",
    "# --------------------------------------------------\n",
    "#url_persistent_id = '%s/api/datasets/:persistentId/add?persistentId=%s' % (dataverse_server, persistentId, api_key)\n",
    "\n",
    "# -------------------\n",
    "# Update the file content to avoid a duplicate file error\n",
    "# -------------------\n",
    "file_content = 'content2: %s' % datetime.now()\n",
    "files = {'file': ('L4_6292_1842a.las', file_content)}\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Make the request\n",
    "# -------------------\n",
    "\n",
    "#r = requests.post(url_persistent_id, data=payload, files=files)\n",
    "\n",
    "# -------------------\n",
    "# Print the response\n",
    "# -------------------\n",
    "\n",
    "#print(r.jsonr.status_code())\n",
    "#print() r.status_code\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's id\n",
    "# --------------------------------------------------\n",
    "#url_dataset_id = '%s/api/datasets/%s/add?key=%s' % (dataverse_server, dataset_id, api_key)\n",
    "#r = requests.post(url_persistent_id, data=payload, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "nuclear-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ok, now do this with the directupload api\n",
    "# https://guides.dataverse.org/en/5.4/developers/s3-direct-upload-api.html\n",
    "#https://guides.dataverse.org/en/5.4/developers/s3-direct-upload-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "straight-yesterday",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Requesting Direct Upload of a DataFile\n",
    "# curl -H 'X-Dataverse-key:$API_TOKEN' \n",
    "#      \"$SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE\"\n",
    "# get pieces and make request\n",
    "#SERVER_URL=https://dataverse.ucla.edu\n",
    "#PERSISTENT_IDENTIFIER=doi:10.25346/S6/T4LHZF\n",
    "#SIZE=10000000\n",
    "dataverse_server = 'https://dataverse.ucla.edu' # no trailing slash\n",
    "persistentId = 'doi:10.25346/S6/T4LHZF' # doi or hdl of the dataset\n",
    "size=10000000\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's persistentId (e.g. doi, hdl, etc)\n",
    "# --------------------------------------------------\n",
    "#    url_dataset_id = '%s/api/datasets/%s/add?key=%s' % (dataverse_server, dataset_id, api_key)\n",
    "#  $SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE\"\n",
    "url_persistent_id = '%s/api/datasets/:persistentId/uploadurls?persistentId=%s&size=%s' % (dataverse_server, persistentId, str(size))\n",
    "\n",
    "#url_persistent_id = '%s/api/datasets/:persistentId/uploadurls?key=%s?persistentId=%s&size=%s' % (dataverse_server, api_key, persistentId, str(size))\n",
    "\n",
    "\n",
    "headers = {'X-Dataverse-key': api_key}\n",
    "# make this into a request:\n",
    "# 'X-Dataverse-key:$API_TOKEN' \n",
    "#      \"/api/datasets/:persistentId/uploadurls?persistentId=$persistentId&size=$size\"\n",
    "#  \n",
    "r = requests.put(url_persistent_id,\n",
    "    headers={\n",
    "        \"X-Dataverse-key\": \"$API_TOKEN\"\n",
    "    },\n",
    "    cookies={},\n",
    "    auth=(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "absent-envelope",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "finnish-onion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'OK', 'data': {'version': '5.3', 'build': '286-fcb5ce7'}}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyDataverse\n",
    "from pyDataverse.api import NativeApi\n",
    "api = NativeApi(dataverse_server, api_key)\n",
    "import subprocess as sp\n",
    "from requests import ConnectionError, Response, delete, get, post, put\n",
    "resp = api.get_info_version()\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-liberty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "pleased-catholic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ERROR',\n",
       " 'code': 405,\n",
       " 'message': 'API endpoint does not support this method. Consult our API guide at http://guides.dataverse.org.',\n",
       " 'requestUrl': 'https://dataverse.ucla.edu/api/v1/datasets/:persistentId/uploadurls?persistentId=doi:10.25346/S6/T4LHZF&size=10000000',\n",
       " 'requestMethod': 'PUT'}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = requests.put(url_persistent_id, data=None, params=None, auth=(), files=None)\n",
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "nutritional-hamilton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Adding the Uploaded file to the Dataset\n",
    "# Once the file exists in the s3 bucket, a final API call is needed to add it to the Dataset. \n",
    "# This call is the same call used to upload a file to a Dataverse installation but, rather than sending the file bytes, \n",
    "# additional metadata is added using the “jsonData” parameter. jsonData normally includes information such as \n",
    "# a file description, tags, provenance, whether the file is restricted, etc. For direct uploads, \n",
    "# the jsonData object must also include values for:\n",
    "# “storageIdentifier” - String, as specified in prior calls\n",
    "# “fileName” - String\n",
    "# “mimeType” - String\n",
    "# “fileSize” - number of bytes\n",
    "# fixity/checksum: either:\n",
    "# “md5Hash” - String with MD5 hash value, or\n",
    "# “checksum” - Json Object with “@type” field specifying the algorithm used and “@value” field with the \n",
    "#   value from that algorithm, both Strings\n",
    "# The allowed checksum algorithms are defined by the edu.harvard.iq.dataverse.DataFile.CheckSumType class and \n",
    "#  currently include MD5, SHA-1, SHA-256, and SHA-512\n",
    "# curl -X POST -H 'X-Dataverse-key: $API_TOKEN' \n",
    "#  \"$SERVER_URL/api/datasets/:persistentId/add?persistentId=#PERSISTENT_IDENTIFIER\" -F 'jsonData=$JSON_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "completed-parks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requests.get(\"$SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE\",\n",
      "    headers={\n",
      "        \"X-Dataverse-key\": \"$API_TOKEN\"\n",
      "    },\n",
      "    cookies={},\n",
      "    auth=(),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import uncurl\n",
    "print(uncurl.parse(\"curl -H 'X-Dataverse-key:$API_TOKEN' '$SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-extension",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
