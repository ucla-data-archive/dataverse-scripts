{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "distinct-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVER_URL=https://dataverse.ucla.edu\n",
    "#PERSISTENT_IDENTIFIER=doi:10.25346/S6/T4LHZF\n",
    "#SIZE=10000000\n",
    "#\n",
    "# token set programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eligible-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyDataverse \n",
    "from pyDataverse.api import NativeApi\n",
    "from pyDataverse.models import Datafile\n",
    "df = Datafile()\n",
    "from datetime import datetime\n",
    "import json   # used to pull in dataverse token\n",
    "import requests  # http://docs.python-requests.org/en/master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "imposed-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Update the 4 params below to run this code\n",
    "# --------------------------------------------------\n",
    "dataverse_server = 'https://dataverse.ucla.edu' # no trailing slash\n",
    "dataset_id = 1  # database id of the dataset\n",
    "persistentId = 'doi:10.25346/S6/T4LHZF' # doi or hdl of the dataset\n",
    "SIZE=10000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "binding-creature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api in separate file\n",
    "with open(\"config.json\") as config:\n",
    "    cfg = json.load(config)\n",
    "# load either dataverse_production or dataverse_test\n",
    "api_key = cfg['dataverse_production']['api_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "opposed-warrior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Prepare \"file\"\n",
    "# --------------------------------------------------\n",
    "file_content = 'content: %s' % datetime.now()\n",
    "files = {'file': ('sample_file.txt', file_content)}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Using a \"jsonData\" parameter, add optional description + file tags\n",
    "# --------------------------------------------------\n",
    "params = dict(description=\"LARIAC4\", categories=[\"LARIAC4\", \"GIS\",\"LAS file\", \"Lidar\"], contentType=\"LAS file Lidar\", restrict=True)\n",
    "\n",
    "params_as_json_string = json.dumps(params)\n",
    "\n",
    "payload = dict(jsonData=params_as_json_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "whole-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's persistentId (e.g. doi, hdl, etc)\n",
    "# --------------------------------------------------\n",
    "#url_persistent_id = '%s/api/datasets/:persistentId/add?persistentId=%s' % (dataverse_server, persistentId, api_key)\n",
    "\n",
    "# -------------------\n",
    "# Update the file content to avoid a duplicate file error\n",
    "# -------------------\n",
    "file_content = 'content2: %s' % datetime.now()\n",
    "files = {'file': ('L4_6292_1842a.las', file_content)}\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Make the request\n",
    "# -------------------\n",
    "\n",
    "#r = requests.post(url_persistent_id, data=payload, files=files)\n",
    "\n",
    "# -------------------\n",
    "# Print the response\n",
    "# -------------------\n",
    "\n",
    "#print(r.jsonr.status_code())\n",
    "#print() r.status_code\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's id\n",
    "# --------------------------------------------------\n",
    "#url_dataset_id = '%s/api/datasets/%s/add?key=%s' % (dataverse_server, dataset_id, api_key)\n",
    "#r = requests.post(url_persistent_id, data=payload, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "general-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Ok, now do this with the directupload api\n",
    "# https://guides.dataverse.org/en/5.4/developers/s3-direct-upload-api.html\n",
    "#https://guides.dataverse.org/en/5.4/developers/s3-direct-upload-api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "vulnerable-florida",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Requesting Direct Upload of a DataFile\n",
    "# curl -H 'X-Dataverse-key:$API_TOKEN' \n",
    "#      \"$SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE\"\n",
    "# get pieces and make request\n",
    "#SERVER_URL=https://dataverse.ucla.edu\n",
    "#PERSISTENT_IDENTIFIER=doi:10.25346/S6/T4LHZF\n",
    "#SIZE=10000000\n",
    "dataverse_server = 'https://dataverse.ucla.edu' # no trailing slash\n",
    "dataset_id = 1  # database id of the dataset\n",
    "persistentId = 'doi:10.25346/S6/T4LHZF' # doi or hdl of the dataset\n",
    "size=10000000\n",
    "\n",
    "# --------------------------------------------------\n",
    "# Add file using the Dataset's persistentId (e.g. doi, hdl, etc)\n",
    "# --------------------------------------------------\n",
    "#    url_dataset_id = '%s/api/datasets/%s/add?key=%s' % (dataverse_server, dataset_id, api_key)\n",
    "#  $SERVER_URL/api/datasets/:persistentId/uploadurls?persistentId=$PERSISTENT_IDENTIFIER&size=$SIZE\"\n",
    "url_persistent_id = '%s/api/datasets/:persistentId/uploadurls?persistentId=%s&size=%s' % (dataverse_server, persistentId, str(size))\n",
    "\n",
    "\n",
    "# make this into a request:\n",
    "# 'X-Dataverse-key:$API_TOKEN' \n",
    "#      \"/api/datasets/:persistentId/uploadurls?persistentId=$persistentId&size=$size\"\n",
    "#  \n",
    "# payload = {'query': json.dumps({\"tags\":[\"test1\", \"test2\"]})}\n",
    "# url = 'http://www.test.com/match'\n",
    "# r = requests.post(url, data=payload)\n",
    "# r = requests.get('https://username.carto.com/endpoint/', auth=(username, 1234567890123456789012345678901234567890))\n",
    "\n",
    "r = requests.post(url_persistent_id, headers={'X-Dataverse-key': 'api_key'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "promising-individual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405\n"
     ]
    }
   ],
   "source": [
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "massive-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Adding the Uploaded file to the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-mexico",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
